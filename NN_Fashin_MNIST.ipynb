{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPbkfKHQqU_1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data FASHION-MNIST and splitting into train- and test- datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "y4y8i7dIqWPY",
    "outputId": "d450fc20-79db-4ff7-e889-d7044d148677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive') #монтируем диск\n",
    "TRAIN_PATH = '/content/gdrive/My Drive/fashion-mnist_train.csv'\n",
    "TEST_PATH = '/content/gdrive/My Drive/fashion-mnist_test.csv'\n",
    "# TRAIN_PATH = './fashion-mnist_train.csv'\n",
    "# TEST_PATH = './fashion-mnist_test.csv'\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDFgVIhLqWXU"
   },
   "outputs": [],
   "source": [
    "X_train = train_df.values[:, 1:]\n",
    "y_train = train_df.values[:, 0]\n",
    "\n",
    "X_test = test_df.values  # [:, 1:]  # удаляем столбец 'label'\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train).view(-1, 1, 28, 28).cuda()\n",
    "y_train_tensor = torch.LongTensor(y_train.astype(np.int64)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting our variables for NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1c-C_PJqWZ1"
   },
   "outputs": [],
   "source": [
    "D_in, D_out = 784, 10\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "learning_rate = 1e-3\n",
    "num_classes = 10  # количество классов, в нашем случае 10 типов одежды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Oh50YTTqWcV"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2))\n",
    "        self.fc1 = nn.Linear(7*7*32, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert into cuda to train our NN on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNa9sntRrpbO"
   },
   "outputs": [],
   "source": [
    "model = CNN(num_classes).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6bi3j0KrtS6"
   },
   "outputs": [],
   "source": [
    "def generate_batches(X, y, batch_size=64):\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        X_batch, y_batch = X[i:i+batch_size], y[i:i+batch_size]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing optimizer SGD and loss function CrossEntropyLoss and training our NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 15371
    },
    "colab_type": "code",
    "id": "NuCx4Z5BsI0y",
    "outputId": "cde9ce33-8cc7-4fd6-fc3f-31451e199d24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100] current loss: 4.3434234085083006\n",
      "[0, 200] current loss: 2.147623987197876\n",
      "[0, 300] current loss: 1.8783226747512818\n",
      "[0, 400] current loss: 1.6927343711853027\n",
      "[0, 500] current loss: 1.6238228273391724\n",
      "[0, 600] current loss: 1.485894588947296\n",
      "[0, 700] current loss: 1.4176460013389587\n",
      "[0, 800] current loss: 1.3237768759727477\n",
      "[0, 900] current loss: 1.336835762500763\n",
      "[1, 100] current loss: 1.224245922088623\n",
      "[1, 200] current loss: 1.1957165565490722\n",
      "[1, 300] current loss: 1.1790027589797973\n",
      "[1, 400] current loss: 1.1245672717094422\n",
      "[1, 500] current loss: 1.1498492636680604\n",
      "[1, 600] current loss: 1.100995904445648\n",
      "[1, 700] current loss: 1.0695583786964415\n",
      "[1, 800] current loss: 1.0468693509101867\n",
      "[1, 900] current loss: 1.0560399651527406\n",
      "[2, 100] current loss: 0.982388279914856\n",
      "[2, 200] current loss: 0.9990334014892578\n",
      "[2, 300] current loss: 0.9948314790725707\n",
      "[2, 400] current loss: 0.9445443913936615\n",
      "[2, 500] current loss: 0.9790902953147889\n",
      "[2, 600] current loss: 0.9411444668769836\n",
      "[2, 700] current loss: 0.9271774904727936\n",
      "[2, 800] current loss: 0.9198905720710754\n",
      "[2, 900] current loss: 0.920466614484787\n",
      "[3, 100] current loss: 0.8680134973526001\n",
      "[3, 200] current loss: 0.8951699500083923\n",
      "[3, 300] current loss: 0.8849206762313843\n",
      "[3, 400] current loss: 0.8394016664028168\n",
      "[3, 500] current loss: 0.8747331922054291\n",
      "[3, 600] current loss: 0.8384054064750671\n",
      "[3, 700] current loss: 0.8428832590579987\n",
      "[3, 800] current loss: 0.8359386768341065\n",
      "[3, 900] current loss: 0.8348532032966614\n",
      "[4, 100] current loss: 0.7879419841766357\n",
      "[4, 200] current loss: 0.8242902755737305\n",
      "[4, 300] current loss: 0.81056565284729\n",
      "[4, 400] current loss: 0.7588354115486144\n",
      "[4, 500] current loss: 0.8038799431324005\n",
      "[4, 600] current loss: 0.764426070690155\n",
      "[4, 700] current loss: 0.7755981326103211\n",
      "[4, 800] current loss: 0.772756156206131\n",
      "[4, 900] current loss: 0.7697420241832733\n",
      "[5, 100] current loss: 0.7285606656074524\n",
      "[5, 200] current loss: 0.7668874478340149\n",
      "[5, 300] current loss: 0.7520087459087372\n",
      "[5, 400] current loss: 0.698311995267868\n",
      "[5, 500] current loss: 0.7488280136585236\n",
      "[5, 600] current loss: 0.7061221694946289\n",
      "[5, 700] current loss: 0.7211616365909577\n",
      "[5, 800] current loss: 0.7201175239086152\n",
      "[5, 900] current loss: 0.7152557139396667\n",
      "[6, 100] current loss: 0.6762269580364227\n",
      "[6, 200] current loss: 0.7179323263168335\n",
      "[6, 300] current loss: 0.6994668638706207\n",
      "[6, 400] current loss: 0.6488870614767075\n",
      "[6, 500] current loss: 0.69581600689888\n",
      "[6, 600] current loss: 0.6557630441188812\n",
      "[6, 700] current loss: 0.6745923776626587\n",
      "[6, 800] current loss: 0.6748287115097046\n",
      "[6, 900] current loss: 0.6675525231361389\n",
      "[7, 100] current loss: 0.6322592825889587\n",
      "[7, 200] current loss: 0.678669921875\n",
      "[7, 300] current loss: 0.6569814829826355\n",
      "[7, 400] current loss: 0.6041478042602539\n",
      "[7, 500] current loss: 0.650744824886322\n",
      "[7, 600] current loss: 0.6122630424499512\n",
      "[7, 700] current loss: 0.6284256858825683\n",
      "[7, 800] current loss: 0.628575035572052\n",
      "[7, 900] current loss: 0.6235770318508148\n",
      "[8, 100] current loss: 0.5833640067577363\n",
      "[8, 200] current loss: 0.636163936138153\n",
      "[8, 300] current loss: 0.6113286054134369\n",
      "[8, 400] current loss: 0.5622875592708587\n",
      "[8, 500] current loss: 0.6098621234893798\n",
      "[8, 600] current loss: 0.5687152667045593\n",
      "[8, 700] current loss: 0.5857315328121185\n",
      "[8, 800] current loss: 0.5869039371013641\n",
      "[8, 900] current loss: 0.5826163127422332\n",
      "[9, 100] current loss: 0.5468658986091613\n",
      "[9, 200] current loss: 0.5981966333389283\n",
      "[9, 300] current loss: 0.5725450067520141\n",
      "[9, 400] current loss: 0.527657898902893\n",
      "[9, 500] current loss: 0.565601304769516\n",
      "[9, 600] current loss: 0.5276364545822143\n",
      "[9, 700] current loss: 0.5495708332061767\n",
      "[9, 800] current loss: 0.5449656360149383\n",
      "[9, 900] current loss: 0.5412406175136566\n",
      "[10, 100] current loss: 0.5080160057544708\n",
      "[10, 200] current loss: 0.5600391038656235\n",
      "[10, 300] current loss: 0.5324800100326538\n",
      "[10, 400] current loss: 0.4934405438899994\n",
      "[10, 500] current loss: 0.5277540414333344\n",
      "[10, 600] current loss: 0.48659109210968016\n",
      "[10, 700] current loss: 0.513383668422699\n",
      "[10, 800] current loss: 0.5080298447608947\n",
      "[10, 900] current loss: 0.5026102955341339\n",
      "[11, 100] current loss: 0.4717717571258545\n",
      "[11, 200] current loss: 0.5275574815273285\n",
      "[11, 300] current loss: 0.49407922506332397\n",
      "[11, 400] current loss: 0.46015952265262605\n",
      "[11, 500] current loss: 0.4890016852617264\n",
      "[11, 600] current loss: 0.44515234875679016\n",
      "[11, 700] current loss: 0.47736861383914947\n",
      "[11, 800] current loss: 0.4774672908782959\n",
      "[11, 900] current loss: 0.4642480515241623\n",
      "[12, 100] current loss: 0.43561362791061403\n",
      "[12, 200] current loss: 0.4880813353061676\n",
      "[12, 300] current loss: 0.46012260150909423\n",
      "[12, 400] current loss: 0.4302880816459656\n",
      "[12, 500] current loss: 0.4522001692056656\n",
      "[12, 600] current loss: 0.4142078835964203\n",
      "[12, 700] current loss: 0.44317849636077883\n",
      "[12, 800] current loss: 0.4370564725399017\n",
      "[12, 900] current loss: 0.4270606008768082\n",
      "[13, 100] current loss: 0.40184894371032714\n",
      "[13, 200] current loss: 0.4502071588039398\n",
      "[13, 300] current loss: 0.42825540709495546\n",
      "[13, 400] current loss: 0.3991021956205368\n",
      "[13, 500] current loss: 0.4121346571445465\n",
      "[13, 600] current loss: 0.3782695791721344\n",
      "[13, 700] current loss: 0.40458173418045046\n",
      "[13, 800] current loss: 0.4024976325035095\n",
      "[13, 900] current loss: 0.39504132759571076\n",
      "[14, 100] current loss: 0.37475833892822263\n",
      "[14, 200] current loss: 0.41460214376449583\n",
      "[14, 300] current loss: 0.395699782371521\n",
      "[14, 400] current loss: 0.36897772300243376\n",
      "[14, 500] current loss: 0.3835851646661758\n",
      "[14, 600] current loss: 0.3423926043510437\n",
      "[14, 700] current loss: 0.3686440041065216\n",
      "[14, 800] current loss: 0.37324134302139284\n",
      "[14, 900] current loss: 0.3557117490768433\n",
      "[15, 100] current loss: 0.34104444181919097\n",
      "[15, 200] current loss: 0.3836469898223877\n",
      "[15, 300] current loss: 0.36452053105831145\n",
      "[15, 400] current loss: 0.33604799044132233\n",
      "[15, 500] current loss: 0.350105366230011\n",
      "[15, 600] current loss: 0.31150906896591185\n",
      "[15, 700] current loss: 0.3362612717151642\n",
      "[15, 800] current loss: 0.34243975389003756\n",
      "[15, 900] current loss: 0.3306081941127777\n",
      "[16, 100] current loss: 0.3131494253873825\n",
      "[16, 200] current loss: 0.34500606095790864\n",
      "[16, 300] current loss: 0.3279884794950485\n",
      "[16, 400] current loss: 0.292396922826767\n",
      "[16, 500] current loss: 0.3195841945409775\n",
      "[16, 600] current loss: 0.2766087324619293\n",
      "[16, 700] current loss: 0.3059743716716766\n",
      "[16, 800] current loss: 0.31345492804050445\n",
      "[16, 900] current loss: 0.30428032207489014\n",
      "[17, 100] current loss: 0.27648126959800723\n",
      "[17, 200] current loss: 0.3049625647068024\n",
      "[17, 300] current loss: 0.3029124603271484\n",
      "[17, 400] current loss: 0.26004962432384493\n",
      "[17, 500] current loss: 0.29678313064575196\n",
      "[17, 600] current loss: 0.25794559490680696\n",
      "[17, 700] current loss: 0.3445276598930359\n",
      "[17, 800] current loss: 0.28519620394706724\n",
      "[17, 900] current loss: 0.2835555843114853\n",
      "[18, 100] current loss: 0.24905500710010528\n",
      "[18, 200] current loss: 0.2878688645362854\n",
      "[18, 300] current loss: 0.2642703945636749\n",
      "[18, 400] current loss: 0.2332498211860657\n",
      "[18, 500] current loss: 0.27324353563785553\n",
      "[18, 600] current loss: 0.23646183514595032\n",
      "[18, 700] current loss: 0.26965146684646607\n",
      "[18, 800] current loss: 0.24345503449440004\n",
      "[18, 900] current loss: 0.2550460474491119\n",
      "[19, 100] current loss: 0.2243096898794174\n",
      "[19, 200] current loss: 0.2685418747663498\n",
      "[19, 300] current loss: 0.24577130842208864\n",
      "[19, 400] current loss: 0.2234967510700226\n",
      "[19, 500] current loss: 0.24409146189689637\n",
      "[19, 600] current loss: 0.20155880510807037\n",
      "[19, 700] current loss: 0.2578217055797577\n",
      "[19, 800] current loss: 0.2800297322273254\n",
      "[19, 900] current loss: 0.24205888700485229\n",
      "[20, 100] current loss: 0.2179421249628067\n",
      "[20, 200] current loss: 0.23856931936740874\n",
      "[20, 300] current loss: 0.20790675640106202\n",
      "[20, 400] current loss: 0.18551251435279847\n",
      "[20, 500] current loss: 0.22489205265045167\n",
      "[20, 600] current loss: 0.18587532937526702\n",
      "[20, 700] current loss: 0.24128908729553222\n",
      "[20, 800] current loss: 0.20465493869781495\n",
      "[20, 900] current loss: 0.2291471402645111\n",
      "[21, 100] current loss: 0.19954586386680603\n",
      "[21, 200] current loss: 0.20994430589675903\n",
      "[21, 300] current loss: 0.20184228312969207\n",
      "[21, 400] current loss: 0.16685030937194825\n",
      "[21, 500] current loss: 0.21017753386497498\n",
      "[21, 600] current loss: 0.20479978621006012\n",
      "[21, 700] current loss: 0.2159026198387146\n",
      "[21, 800] current loss: 0.18099278724193574\n",
      "[21, 900] current loss: 0.2130718002319336\n",
      "[22, 100] current loss: 0.17472984552383422\n",
      "[22, 200] current loss: 0.20598818898200988\n",
      "[22, 300] current loss: 0.18141319513320922\n",
      "[22, 400] current loss: 0.18781426453590394\n",
      "[22, 500] current loss: 0.22625667762756346\n",
      "[22, 600] current loss: 0.19578700041770936\n",
      "[22, 700] current loss: 0.19780485248565674\n",
      "[22, 800] current loss: 0.16936853659152984\n",
      "[22, 900] current loss: 0.18764473283290864\n",
      "[23, 100] current loss: 0.14897881436347962\n",
      "[23, 200] current loss: 0.21107512903213502\n",
      "[23, 300] current loss: 0.17019337582588195\n",
      "[23, 400] current loss: 0.18029557275772096\n",
      "[23, 500] current loss: 0.18745813417434692\n",
      "[23, 600] current loss: 0.16341490042209625\n",
      "[23, 700] current loss: 0.15529677641391754\n",
      "[23, 800] current loss: 0.18831534624099733\n",
      "[23, 900] current loss: 0.1719971158504486\n",
      "[24, 100] current loss: 0.22329011368751525\n",
      "[24, 200] current loss: 0.17125865137577057\n",
      "[24, 300] current loss: 0.1539461796283722\n",
      "[24, 400] current loss: 0.17244107127189637\n",
      "[24, 500] current loss: 0.16013911819458007\n",
      "[24, 600] current loss: 0.1378745834827423\n",
      "[24, 700] current loss: 0.17724103164672853\n",
      "[24, 800] current loss: 0.15477467823028565\n",
      "[24, 900] current loss: 0.1637601146697998\n",
      "[25, 100] current loss: 0.13295455050468444\n",
      "[25, 200] current loss: 0.1520023891925812\n",
      "[25, 300] current loss: 0.14909783411026\n",
      "[25, 400] current loss: 0.15086751389503478\n",
      "[25, 500] current loss: 0.13443044650554656\n",
      "[25, 600] current loss: 0.13209876585006713\n",
      "[25, 700] current loss: 0.1421513638496399\n",
      "[25, 800] current loss: 0.12737786841392518\n",
      "[25, 900] current loss: 0.14098385787010193\n",
      "[26, 100] current loss: 0.1369467146396637\n",
      "[26, 200] current loss: 0.13280394196510314\n",
      "[26, 300] current loss: 0.12259231734275818\n",
      "[26, 400] current loss: 0.12314182734489441\n",
      "[26, 500] current loss: 0.13523312425613404\n",
      "[26, 600] current loss: 0.11178468489646912\n",
      "[26, 700] current loss: 0.19911480712890625\n",
      "[26, 800] current loss: 0.14884429013729095\n",
      "[26, 900] current loss: 0.1649871940612793\n",
      "[27, 100] current loss: 0.19340735578536988\n",
      "[27, 200] current loss: 0.1227776141166687\n",
      "[27, 300] current loss: 0.13910005044937135\n",
      "[27, 400] current loss: 0.11811510157585144\n",
      "[27, 500] current loss: 0.13809126949310302\n",
      "[27, 600] current loss: 0.11795631170272827\n",
      "[27, 700] current loss: 0.14069073295593262\n",
      "[27, 800] current loss: 0.11600513982772827\n",
      "[27, 900] current loss: 0.1507873400449753\n",
      "[28, 100] current loss: 0.1345827534198761\n",
      "[28, 200] current loss: 0.10475852799415589\n",
      "[28, 300] current loss: 0.10241539144515992\n",
      "[28, 400] current loss: 0.09227019429206848\n",
      "[28, 500] current loss: 0.11036629676818847\n",
      "[28, 600] current loss: 0.09891877031326293\n",
      "[28, 700] current loss: 0.0939607093334198\n",
      "[28, 800] current loss: 0.10525661695003509\n",
      "[28, 900] current loss: 0.11901360929012299\n",
      "[29, 100] current loss: 0.10441078305244446\n",
      "[29, 200] current loss: 0.11404943799972535\n",
      "[29, 300] current loss: 0.08349504613876343\n",
      "[29, 400] current loss: 0.07323031044006348\n",
      "[29, 500] current loss: 0.09715595555305481\n",
      "[29, 600] current loss: 0.10719336128234863\n",
      "[29, 700] current loss: 0.08972885954380036\n",
      "[29, 800] current loss: 0.08928724265098571\n",
      "[29, 900] current loss: 0.07830208706855774\n",
      "[30, 100] current loss: 0.1131025664806366\n",
      "[30, 200] current loss: 0.1138506498336792\n",
      "[30, 300] current loss: 0.07431618738174438\n",
      "[30, 400] current loss: 0.07135845112800598\n",
      "[30, 500] current loss: 0.12397029519081115\n",
      "[30, 600] current loss: 0.12324330759048462\n",
      "[30, 700] current loss: 0.09998771691322327\n",
      "[30, 800] current loss: 0.10879993915557862\n",
      "[30, 900] current loss: 0.08480390930175781\n",
      "[31, 100] current loss: 0.11691518044471741\n",
      "[31, 200] current loss: 0.09725440311431885\n",
      "[31, 300] current loss: 0.06760606026649475\n",
      "[31, 400] current loss: 0.10294286823272705\n",
      "[31, 500] current loss: 0.10398695063591003\n",
      "[31, 600] current loss: 0.07418502140045166\n",
      "[31, 700] current loss: 0.12470919060707092\n",
      "[31, 800] current loss: 0.0970908019542694\n",
      "[31, 900] current loss: 0.08559751844406129\n",
      "[32, 100] current loss: 0.08155154824256897\n",
      "[32, 200] current loss: 0.10331716895103454\n",
      "[32, 300] current loss: 0.06925954031944274\n",
      "[32, 400] current loss: 0.07411626482009888\n",
      "[32, 500] current loss: 0.08068753719329834\n",
      "[32, 600] current loss: 0.10547916460037231\n",
      "[32, 700] current loss: 0.10322186398506164\n",
      "[32, 800] current loss: 0.08062676358222962\n",
      "[32, 900] current loss: 0.08000677251815796\n",
      "[33, 100] current loss: 0.09289139366149902\n",
      "[33, 200] current loss: 0.07345418810844422\n",
      "[33, 300] current loss: 0.06715473651885986\n",
      "[33, 400] current loss: 0.0686181309223175\n",
      "[33, 500] current loss: 0.08918082058429717\n",
      "[33, 600] current loss: 0.07409051942825318\n",
      "[33, 700] current loss: 0.11825827836990356\n",
      "[33, 800] current loss: 0.06630791974067687\n",
      "[33, 900] current loss: 0.08739832544326782\n",
      "[34, 100] current loss: 0.07618071913719177\n",
      "[34, 200] current loss: 0.08561165523529053\n",
      "[34, 300] current loss: 0.06611728167533874\n",
      "[34, 400] current loss: 0.07323368740081787\n",
      "[34, 500] current loss: 0.10180498826503753\n",
      "[34, 600] current loss: 0.0816952919960022\n",
      "[34, 700] current loss: 0.12101305675506592\n",
      "[34, 800] current loss: 0.05007369875907898\n",
      "[34, 900] current loss: 0.07079713726043702\n",
      "[35, 100] current loss: 0.0698357219696045\n",
      "[35, 200] current loss: 0.0609508626461029\n",
      "[35, 300] current loss: 0.06294345641136169\n",
      "[35, 400] current loss: 0.06348663592338562\n",
      "[35, 500] current loss: 0.050445172071456906\n",
      "[35, 600] current loss: 0.041694674730300904\n",
      "[35, 700] current loss: 0.059053805589675906\n",
      "[35, 800] current loss: 0.04519980144500733\n",
      "[35, 900] current loss: 0.07212287640571594\n",
      "[36, 100] current loss: 0.05728360414505005\n",
      "[36, 200] current loss: 0.05359124493598938\n",
      "[36, 300] current loss: 0.0746687514781952\n",
      "[36, 400] current loss: 0.06414717078208923\n",
      "[36, 500] current loss: 0.07944590592384339\n",
      "[36, 600] current loss: 0.03856692886352539\n",
      "[36, 700] current loss: 0.06538799476623536\n",
      "[36, 800] current loss: 0.057492581367492676\n",
      "[36, 900] current loss: 0.05388249611854553\n",
      "[37, 100] current loss: 0.04014138174057007\n",
      "[37, 200] current loss: 0.0449903416633606\n",
      "[37, 300] current loss: 0.06617396855354309\n",
      "[37, 400] current loss: 0.0583143048286438\n",
      "[37, 500] current loss: 0.07405850028991699\n",
      "[37, 600] current loss: 0.07137185978889465\n",
      "[37, 700] current loss: 0.0556734676361084\n",
      "[37, 800] current loss: 0.05660589861869812\n",
      "[37, 900] current loss: 0.05598436903953552\n",
      "[38, 100] current loss: 0.10792651677131652\n",
      "[38, 200] current loss: 0.08253399085998535\n",
      "[38, 300] current loss: 0.04877871584892273\n",
      "[38, 400] current loss: 0.09580934524536133\n",
      "[38, 500] current loss: 0.06788603401184082\n",
      "[38, 600] current loss: 0.09123371911048889\n",
      "[38, 700] current loss: 0.08420318818092346\n",
      "[38, 800] current loss: 0.05062067461013794\n",
      "[38, 900] current loss: 0.053943994522094724\n",
      "[39, 100] current loss: 0.06981590938568115\n",
      "[39, 200] current loss: 0.10045705795288086\n",
      "[39, 300] current loss: 0.048195152759552\n",
      "[39, 400] current loss: 0.06260883212089538\n",
      "[39, 500] current loss: 0.07896971368789672\n",
      "[39, 600] current loss: 0.0545227313041687\n",
      "[39, 700] current loss: 0.0628651852607727\n",
      "[39, 800] current loss: 0.04343019199371338\n",
      "[39, 900] current loss: 0.05516844773292542\n",
      "[40, 100] current loss: 0.0434213297367096\n",
      "[40, 200] current loss: 0.06525216579437255\n",
      "[40, 300] current loss: 0.0689138104915619\n",
      "[40, 400] current loss: 0.04752372860908508\n",
      "[40, 500] current loss: 0.039556711673736575\n",
      "[40, 600] current loss: 0.04859605884552002\n",
      "[40, 700] current loss: 0.05535725259780884\n",
      "[40, 800] current loss: 0.04895710349082947\n",
      "[40, 900] current loss: 0.059701730489730834\n",
      "[41, 100] current loss: 0.032317874908447265\n",
      "[41, 200] current loss: 0.05608446383476257\n",
      "[41, 300] current loss: 0.09863677811622619\n",
      "[41, 400] current loss: 0.06123140120506287\n",
      "[41, 500] current loss: 0.062309132099151614\n",
      "[41, 600] current loss: 0.05098395609855652\n",
      "[41, 700] current loss: 0.05475555109977722\n",
      "[41, 800] current loss: 0.06225093960762024\n",
      "[41, 900] current loss: 0.0350008635520935\n",
      "[42, 100] current loss: 0.04576938199996948\n",
      "[42, 200] current loss: 0.04113657307624817\n",
      "[42, 300] current loss: 0.028635820865631104\n",
      "[42, 400] current loss: 0.023951930046081545\n",
      "[42, 500] current loss: 0.03381130409240723\n",
      "[42, 600] current loss: 0.026067373752593995\n",
      "[42, 700] current loss: 0.03086396026611328\n",
      "[42, 800] current loss: 0.043270902156829834\n",
      "[42, 900] current loss: 0.03501095175743103\n",
      "[43, 100] current loss: 0.029919628143310548\n",
      "[43, 200] current loss: 0.030921826362609862\n",
      "[43, 300] current loss: 0.015252871990203858\n",
      "[43, 400] current loss: 0.022615899562835693\n",
      "[43, 500] current loss: 0.03135243725776672\n",
      "[43, 600] current loss: 0.027932443618774415\n",
      "[43, 700] current loss: 0.03196860408782959\n",
      "[43, 800] current loss: 0.02539232087135315\n",
      "[43, 900] current loss: 0.03605570721626282\n",
      "[44, 100] current loss: 0.02612755751609802\n",
      "[44, 200] current loss: 0.022597084283828735\n",
      "[44, 300] current loss: 0.0915427017211914\n",
      "[44, 400] current loss: 0.06570376539230346\n",
      "[44, 500] current loss: 0.024175997257232667\n",
      "[44, 600] current loss: 0.04629209589958191\n",
      "[44, 700] current loss: 0.07271063661575318\n",
      "[44, 800] current loss: 0.04214645218849182\n",
      "[44, 900] current loss: 0.03181818461418152\n",
      "[45, 100] current loss: 0.03444276738166809\n",
      "[45, 200] current loss: 0.046672829866409304\n",
      "[45, 300] current loss: 0.05718526291847229\n",
      "[45, 400] current loss: 0.037060259342193605\n",
      "[45, 500] current loss: 0.039728206634521486\n",
      "[45, 600] current loss: 0.037928067445755005\n",
      "[45, 700] current loss: 0.02219827127456665\n",
      "[45, 800] current loss: 0.02761463642120361\n",
      "[45, 900] current loss: 0.034228560447692874\n",
      "[46, 100] current loss: 0.029810918807983398\n",
      "[46, 200] current loss: 0.0242643358707428\n",
      "[46, 300] current loss: 0.027253772497177125\n",
      "[46, 400] current loss: 0.06364953708648681\n",
      "[46, 500] current loss: 0.052485593795776365\n",
      "[46, 600] current loss: 0.059927968502044675\n",
      "[46, 700] current loss: 0.04280578780174255\n",
      "[46, 800] current loss: 0.044251776456832884\n",
      "[46, 900] current loss: 0.022999277353286742\n",
      "[47, 100] current loss: 0.022167293548583985\n",
      "[47, 200] current loss: 0.028083701848983764\n",
      "[47, 300] current loss: 0.015714241027832032\n",
      "[47, 400] current loss: 0.030662662267684937\n",
      "[47, 500] current loss: 0.046550758123397824\n",
      "[47, 600] current loss: 0.04640717196464539\n",
      "[47, 700] current loss: 0.030665487051010132\n",
      "[47, 800] current loss: 0.027089455366134642\n",
      "[47, 900] current loss: 0.04505613327026367\n",
      "[48, 100] current loss: 0.025857887506484985\n",
      "[48, 200] current loss: 0.02716351246833801\n",
      "[48, 300] current loss: 0.05921401691436767\n",
      "[48, 400] current loss: 0.03331807565689087\n",
      "[48, 500] current loss: 0.029399534225463868\n",
      "[48, 600] current loss: 0.023852519989013672\n",
      "[48, 700] current loss: 0.03071922826766968\n",
      "[48, 800] current loss: 0.039716019868850705\n",
      "[48, 900] current loss: 0.05054675006866455\n",
      "[49, 100] current loss: 0.029517906188964844\n",
      "[49, 200] current loss: 0.053288623094558715\n",
      "[49, 300] current loss: 0.021937578201293946\n",
      "[49, 400] current loss: 0.02598078107833862\n",
      "[49, 500] current loss: 0.02340022325515747\n",
      "[49, 600] current loss: 0.05045705056190491\n",
      "[49, 700] current loss: 0.047729119062423705\n",
      "[49, 800] current loss: 0.02631684374809265\n",
      "[49, 900] current loss: 0.018120965242385864\n",
      "[50, 100] current loss: 0.046212253093719485\n",
      "[50, 200] current loss: 0.04672116184234619\n",
      "[50, 300] current loss: 0.02870474076271057\n",
      "[50, 400] current loss: 0.04710405278205872\n",
      "[50, 500] current loss: 0.04782426118850708\n",
      "[50, 600] current loss: 0.04972512531280517\n",
      "[50, 700] current loss: 0.052583109617233274\n",
      "[50, 800] current loss: 0.03089279532432556\n",
      "[50, 900] current loss: 0.020891084671020507\n",
      "[51, 100] current loss: 0.041785257339477536\n",
      "[51, 200] current loss: 0.02710526466369629\n",
      "[51, 300] current loss: 0.025498964309692382\n",
      "[51, 400] current loss: 0.018251153230667113\n",
      "[51, 500] current loss: 0.016856383085250854\n",
      "[51, 600] current loss: 0.013017970085144043\n",
      "[51, 700] current loss: 0.020706300735473634\n",
      "[51, 800] current loss: 0.02520502805709839\n",
      "[51, 900] current loss: 0.012447879314422608\n",
      "[52, 100] current loss: 0.021290359497070314\n",
      "[52, 200] current loss: 0.017786369800567626\n",
      "[52, 300] current loss: 0.013792463064193726\n",
      "[52, 400] current loss: 0.018021247863769532\n",
      "[52, 500] current loss: 0.013560513019561767\n",
      "[52, 600] current loss: 0.009960474014282227\n",
      "[52, 700] current loss: 0.013640169620513915\n",
      "[52, 800] current loss: 0.145554434299469\n",
      "[52, 900] current loss: 0.06201004815101623\n",
      "[53, 100] current loss: 0.02439286804199219\n",
      "[53, 200] current loss: 0.025135850429534912\n",
      "[53, 300] current loss: 0.011881875991821288\n",
      "[53, 400] current loss: 0.014651900768280029\n",
      "[53, 500] current loss: 0.018405848741531373\n",
      "[53, 600] current loss: 0.031235836744308472\n",
      "[53, 700] current loss: 0.03371844100952148\n",
      "[53, 800] current loss: 0.019008853673934935\n",
      "[53, 900] current loss: 0.01260034966468811\n",
      "[54, 100] current loss: 0.011621030807495117\n",
      "[54, 200] current loss: 0.01127823305130005\n",
      "[54, 300] current loss: 0.007478091239929199\n",
      "[54, 400] current loss: 0.009150983333587647\n",
      "[54, 500] current loss: 0.006532866477966309\n",
      "[54, 600] current loss: 0.010876493453979492\n",
      "[54, 700] current loss: 0.01110892629623413\n",
      "[54, 800] current loss: 0.013842042922973632\n",
      "[54, 900] current loss: 0.030965466737747194\n",
      "[55, 100] current loss: 0.012825546026229859\n",
      "[55, 200] current loss: 0.014629872798919677\n",
      "[55, 300] current loss: 0.021003254890441893\n",
      "[55, 400] current loss: 0.01772558283805847\n",
      "[55, 500] current loss: 0.010531770706176757\n",
      "[55, 600] current loss: 0.0085088791847229\n",
      "[55, 700] current loss: 0.01905982494354248\n",
      "[55, 800] current loss: 0.016503955364227295\n",
      "[55, 900] current loss: 0.021982404947280883\n",
      "[56, 100] current loss: 0.008259033679962158\n",
      "[56, 200] current loss: 0.00838492202758789\n",
      "[56, 300] current loss: 0.008912057399749755\n",
      "[56, 400] current loss: 0.03028274965286255\n",
      "[56, 500] current loss: 0.031341487884521485\n",
      "[56, 600] current loss: 0.020127780914306642\n",
      "[56, 700] current loss: 0.020928411483764647\n",
      "[56, 800] current loss: 0.008036246299743652\n",
      "[56, 900] current loss: 0.009807894706726075\n",
      "[57, 100] current loss: 0.009472869396209716\n",
      "[57, 200] current loss: 0.0074517502784729\n",
      "[57, 300] current loss: 0.011427438259124756\n",
      "[57, 400] current loss: 0.00974887466430664\n",
      "[57, 500] current loss: 0.007187860488891602\n",
      "[57, 600] current loss: 0.006132024765014649\n",
      "[57, 700] current loss: 0.006733840465545655\n",
      "[57, 800] current loss: 0.011937172889709472\n",
      "[57, 900] current loss: 0.017115417003631592\n",
      "[58, 100] current loss: 0.008030069828033446\n",
      "[58, 200] current loss: 0.011927517414093017\n",
      "[58, 300] current loss: 0.004889586448669434\n",
      "[58, 400] current loss: 0.004491968154907227\n",
      "[58, 500] current loss: 0.005322319507598877\n",
      "[58, 600] current loss: 0.003794126510620117\n",
      "[58, 700] current loss: 0.007309000492095947\n",
      "[58, 800] current loss: 0.005452429294586182\n",
      "[58, 900] current loss: 0.0038603370189666747\n",
      "[59, 100] current loss: 0.010839149475097657\n",
      "[59, 200] current loss: 0.005183640003204345\n",
      "[59, 300] current loss: 0.0035367488861083986\n",
      "[59, 400] current loss: 0.0029949564933776855\n",
      "[59, 500] current loss: 0.003725263595581055\n",
      "[59, 600] current loss: 0.0020468358993530273\n",
      "[59, 700] current loss: 0.0034836897850036622\n",
      "[59, 800] current loss: 0.003003265380859375\n",
      "[59, 900] current loss: 0.003004091262817383\n",
      "[60, 100] current loss: 0.0027083911895751955\n",
      "[60, 200] current loss: 0.003227128982543945\n",
      "[60, 300] current loss: 0.002738448143005371\n",
      "[60, 400] current loss: 0.0020099377632141115\n",
      "[60, 500] current loss: 0.001653724193572998\n",
      "[60, 600] current loss: 0.0017976078987121582\n",
      "[60, 700] current loss: 0.0024820713996887207\n",
      "[60, 800] current loss: 0.0020020108222961424\n",
      "[60, 900] current loss: 0.0018435912132263184\n",
      "[61, 100] current loss: 0.0015345206260681153\n",
      "[61, 200] current loss: 0.0025165376663208007\n",
      "[61, 300] current loss: 0.002126283645629883\n",
      "[61, 400] current loss: 0.001519914150238037\n",
      "[61, 500] current loss: 0.001235246181488037\n",
      "[61, 600] current loss: 0.0013619027137756349\n",
      "[61, 700] current loss: 0.002077992916107178\n",
      "[61, 800] current loss: 0.0015719103813171386\n",
      "[61, 900] current loss: 0.0014969367980957032\n",
      "[62, 100] current loss: 0.0011911005973815917\n",
      "[62, 200] current loss: 0.0018677759170532228\n",
      "[62, 300] current loss: 0.001590620517730713\n",
      "[62, 400] current loss: 0.0012797961235046387\n",
      "[62, 500] current loss: 0.0009317436218261719\n",
      "[62, 600] current loss: 0.0010724945068359376\n",
      "[62, 700] current loss: 0.0017162985801696777\n",
      "[62, 800] current loss: 0.001335202693939209\n",
      "[62, 900] current loss: 0.0012195272445678711\n",
      "[63, 100] current loss: 0.0009569621086120605\n",
      "[63, 200] current loss: 0.0015786924362182616\n",
      "[63, 300] current loss: 0.0012923789024353028\n",
      "[63, 400] current loss: 0.0010688223838806153\n",
      "[63, 500] current loss: 0.0008001337051391601\n",
      "[63, 600] current loss: 0.0009138875007629394\n",
      "[63, 700] current loss: 0.0014942326545715331\n",
      "[63, 800] current loss: 0.0011309232711791991\n",
      "[63, 900] current loss: 0.001062681198120117\n",
      "[64, 100] current loss: 0.0008283262252807617\n",
      "[64, 200] current loss: 0.00137489652633667\n",
      "[64, 300] current loss: 0.001116832733154297\n",
      "[64, 400] current loss: 0.0009416046142578125\n",
      "[64, 500] current loss: 0.0007176966667175293\n",
      "[64, 600] current loss: 0.0008009343147277832\n",
      "[64, 700] current loss: 0.0013348073959350585\n",
      "[64, 800] current loss: 0.0010061850547790528\n",
      "[64, 900] current loss: 0.0009447221755981446\n",
      "[65, 100] current loss: 0.000735011100769043\n",
      "[65, 200] current loss: 0.001227560520172119\n",
      "[65, 300] current loss: 0.0009978008270263672\n",
      "[65, 400] current loss: 0.0008605237007141113\n",
      "[65, 500] current loss: 0.0006518378257751465\n",
      "[65, 600] current loss: 0.0007198486328125\n",
      "[65, 700] current loss: 0.0011984128952026367\n",
      "[65, 800] current loss: 0.0009084954261779785\n",
      "[65, 900] current loss: 0.0008479022979736328\n",
      "[66, 100] current loss: 0.000656827449798584\n",
      "[66, 200] current loss: 0.0011050477027893066\n",
      "[66, 300] current loss: 0.0008967599868774414\n",
      "[66, 400] current loss: 0.0007815022468566895\n",
      "[66, 500] current loss: 0.0005999188423156739\n",
      "[66, 600] current loss: 0.0006572728157043457\n",
      "[66, 700] current loss: 0.001082709789276123\n",
      "[66, 800] current loss: 0.0008252553939819336\n",
      "[66, 900] current loss: 0.000777653694152832\n",
      "[67, 100] current loss: 0.000597465991973877\n",
      "[67, 200] current loss: 0.0009999070167541503\n",
      "[67, 300] current loss: 0.0008127231597900391\n",
      "[67, 400] current loss: 0.0007145357131958008\n",
      "[67, 500] current loss: 0.0005568490028381348\n",
      "[67, 600] current loss: 0.0006031394004821777\n",
      "[67, 700] current loss: 0.0009776630401611328\n",
      "[67, 800] current loss: 0.0007593221664428711\n",
      "[67, 900] current loss: 0.0007147841453552246\n",
      "[68, 100] current loss: 0.0005460028648376465\n",
      "[68, 200] current loss: 0.0009139714241027832\n",
      "[68, 300] current loss: 0.0007465543746948242\n",
      "[68, 400] current loss: 0.0006605539321899414\n",
      "[68, 500] current loss: 0.0005210165977478028\n",
      "[68, 600] current loss: 0.0005595912933349609\n",
      "[68, 700] current loss: 0.0008987116813659667\n",
      "[68, 800] current loss: 0.0006979012489318848\n",
      "[68, 900] current loss: 0.0006658515930175782\n",
      "[69, 100] current loss: 0.0005060806274414062\n",
      "[69, 200] current loss: 0.0008421306610107422\n",
      "[69, 300] current loss: 0.0006859555244445801\n",
      "[69, 400] current loss: 0.0006179022789001465\n",
      "[69, 500] current loss: 0.0004897279739379883\n",
      "[69, 600] current loss: 0.0005214562416076661\n",
      "[69, 700] current loss: 0.0008252573013305664\n",
      "[69, 800] current loss: 0.0006447634696960449\n",
      "[69, 900] current loss: 0.000620295524597168\n",
      "[70, 100] current loss: 0.00047154569625854493\n",
      "[70, 200] current loss: 0.0007807092666625977\n",
      "[70, 300] current loss: 0.0006349205970764161\n",
      "[70, 400] current loss: 0.0005778489112854004\n",
      "[70, 500] current loss: 0.0004614863395690918\n",
      "[70, 600] current loss: 0.0004895048141479492\n",
      "[70, 700] current loss: 0.0007711482048034668\n",
      "[70, 800] current loss: 0.0006009259223937988\n",
      "[70, 900] current loss: 0.0005826020240783692\n",
      "[71, 100] current loss: 0.0004430222511291504\n",
      "[71, 200] current loss: 0.0007269406318664551\n",
      "[71, 300] current loss: 0.0005931596755981445\n",
      "[71, 400] current loss: 0.0005403547286987304\n",
      "[71, 500] current loss: 0.00043558454513549803\n",
      "[71, 600] current loss: 0.000461761474609375\n",
      "[71, 700] current loss: 0.0007199254035949707\n",
      "[71, 800] current loss: 0.0005608205795288086\n",
      "[71, 900] current loss: 0.0005490822792053223\n",
      "[72, 100] current loss: 0.0004160933494567871\n",
      "[72, 200] current loss: 0.0006801891326904297\n",
      "[72, 300] current loss: 0.0005562849044799805\n",
      "[72, 400] current loss: 0.0005114831924438476\n",
      "[72, 500] current loss: 0.00041450309753417967\n",
      "[72, 600] current loss: 0.00043667316436767577\n",
      "[72, 700] current loss: 0.0006735000610351563\n",
      "[72, 800] current loss: 0.0005253005027770996\n",
      "[72, 900] current loss: 0.0005209550857543945\n",
      "[73, 100] current loss: 0.00039314460754394533\n",
      "[73, 200] current loss: 0.0006391491889953613\n",
      "[73, 300] current loss: 0.0005198736190795898\n",
      "[73, 400] current loss: 0.0004826536178588867\n",
      "[73, 500] current loss: 0.0003948235511779785\n",
      "[73, 600] current loss: 0.000414639949798584\n",
      "[73, 700] current loss: 0.0006323409080505371\n",
      "[73, 800] current loss: 0.0004948868751525879\n",
      "[73, 900] current loss: 0.0004949183464050293\n",
      "[74, 100] current loss: 0.0003733067512512207\n",
      "[74, 200] current loss: 0.0006016316413879394\n",
      "[74, 300] current loss: 0.0004901900291442871\n",
      "[74, 400] current loss: 0.000457061767578125\n",
      "[74, 500] current loss: 0.00037697458267211913\n",
      "[74, 600] current loss: 0.00039703941345214846\n",
      "[74, 700] current loss: 0.0005943174362182617\n",
      "[74, 800] current loss: 0.000468536376953125\n",
      "[74, 900] current loss: 0.0004735760688781738\n",
      "[75, 100] current loss: 0.0003553628921508789\n",
      "[75, 200] current loss: 0.0005698108673095703\n",
      "[75, 300] current loss: 0.00046215152740478516\n",
      "[75, 400] current loss: 0.0004328041076660156\n",
      "[75, 500] current loss: 0.00036195230484008787\n",
      "[75, 600] current loss: 0.0003793058395385742\n",
      "[75, 700] current loss: 0.0005600485801696778\n",
      "[75, 800] current loss: 0.0004430685043334961\n",
      "[75, 900] current loss: 0.0004511404037475586\n",
      "[76, 100] current loss: 0.00033878660202026366\n",
      "[76, 200] current loss: 0.0005415840148925782\n",
      "[76, 300] current loss: 0.00043846511840820313\n",
      "[76, 400] current loss: 0.0004114747047424316\n",
      "[76, 500] current loss: 0.0003466472625732422\n",
      "[76, 600] current loss: 0.0003636584281921387\n",
      "[76, 700] current loss: 0.0005310101509094238\n",
      "[76, 800] current loss: 0.0004237198829650879\n",
      "[76, 900] current loss: 0.00043212890625\n",
      "[77, 100] current loss: 0.00032293367385864257\n",
      "[77, 200] current loss: 0.0005135664939880371\n",
      "[77, 300] current loss: 0.00041729497909545897\n",
      "[77, 400] current loss: 0.0003918471336364746\n",
      "[77, 500] current loss: 0.0003337559700012207\n",
      "[77, 600] current loss: 0.0003482351303100586\n",
      "[77, 700] current loss: 0.000505216121673584\n",
      "[77, 800] current loss: 0.00040406036376953124\n",
      "[77, 900] current loss: 0.0004140892028808594\n",
      "[78, 100] current loss: 0.0003094959259033203\n",
      "[78, 200] current loss: 0.0004894638061523438\n",
      "[78, 300] current loss: 0.00039772891998291014\n",
      "[78, 400] current loss: 0.0003740615844726563\n",
      "[78, 500] current loss: 0.00031975507736206057\n",
      "[78, 600] current loss: 0.0003342499732971191\n",
      "[78, 700] current loss: 0.00048026466369628906\n",
      "[78, 800] current loss: 0.00038587427139282225\n",
      "[78, 900] current loss: 0.00039776325225830076\n",
      "[79, 100] current loss: 0.00029743146896362305\n",
      "[79, 200] current loss: 0.0004673781394958496\n",
      "[79, 300] current loss: 0.00038033056259155273\n",
      "[79, 400] current loss: 0.0003572573661804199\n",
      "[79, 500] current loss: 0.0003082566261291504\n",
      "[79, 600] current loss: 0.0003216543197631836\n",
      "[79, 700] current loss: 0.00045861053466796873\n",
      "[79, 800] current loss: 0.0003694591522216797\n",
      "[79, 900] current loss: 0.0003823981285095215\n",
      "[80, 100] current loss: 0.0002859349250793457\n",
      "[80, 200] current loss: 0.0004465079307556152\n",
      "[80, 300] current loss: 0.00036395263671875\n",
      "[80, 400] current loss: 0.00034296751022338867\n",
      "[80, 500] current loss: 0.0002979745864868164\n",
      "[80, 600] current loss: 0.00030979251861572266\n",
      "[80, 700] current loss: 0.0004380450248718262\n",
      "[80, 800] current loss: 0.00035504150390625\n",
      "[80, 900] current loss: 0.000367490291595459\n",
      "[81, 100] current loss: 0.00027447891235351564\n",
      "[81, 200] current loss: 0.00042723941802978515\n",
      "[81, 300] current loss: 0.0003491535186767578\n",
      "[81, 400] current loss: 0.00033012056350708007\n",
      "[81, 500] current loss: 0.0002882800102233887\n",
      "[81, 600] current loss: 0.0002990880012512207\n",
      "[81, 700] current loss: 0.0004194808006286621\n",
      "[81, 800] current loss: 0.0003419036865234375\n",
      "[81, 900] current loss: 0.0003547525405883789\n",
      "[82, 100] current loss: 0.00026508235931396485\n",
      "[82, 200] current loss: 0.0004110569953918457\n",
      "[82, 300] current loss: 0.0003355565071105957\n",
      "[82, 400] current loss: 0.00031709957122802733\n",
      "[82, 500] current loss: 0.0002791914939880371\n",
      "[82, 600] current loss: 0.0002888679504394531\n",
      "[82, 700] current loss: 0.00040302419662475585\n",
      "[82, 800] current loss: 0.00032906055450439455\n",
      "[82, 900] current loss: 0.00034284162521362304\n",
      "[83, 100] current loss: 0.0002554416656494141\n",
      "[83, 200] current loss: 0.00039544343948364255\n",
      "[83, 300] current loss: 0.0003223361968994141\n",
      "[83, 400] current loss: 0.0003053245544433594\n",
      "[83, 500] current loss: 0.0002703084945678711\n",
      "[83, 600] current loss: 0.0002797088623046875\n",
      "[83, 700] current loss: 0.0003868889808654785\n",
      "[83, 800] current loss: 0.00031702280044555665\n",
      "[83, 900] current loss: 0.00033169984817504883\n",
      "[84, 100] current loss: 0.0002475714683532715\n",
      "[84, 200] current loss: 0.0003802013397216797\n",
      "[84, 300] current loss: 0.00031076908111572266\n",
      "[84, 400] current loss: 0.00029523563385009765\n",
      "[84, 500] current loss: 0.00026142215728759764\n",
      "[84, 600] current loss: 0.00027059125900268555\n",
      "[84, 700] current loss: 0.00037236309051513674\n",
      "[84, 800] current loss: 0.00030639123916625976\n",
      "[84, 900] current loss: 0.00032130765914916993\n",
      "[85, 100] current loss: 0.00023973846435546874\n",
      "[85, 200] current loss: 0.000366818904876709\n",
      "[85, 300] current loss: 0.00029982471466064454\n",
      "[85, 400] current loss: 0.00028420686721801757\n",
      "[85, 500] current loss: 0.00025388193130493163\n",
      "[85, 600] current loss: 0.0002626614570617676\n",
      "[85, 700] current loss: 0.0003584871292114258\n",
      "[85, 800] current loss: 0.00029564619064331054\n",
      "[85, 900] current loss: 0.0003108248710632324\n",
      "[86, 100] current loss: 0.0002320232391357422\n",
      "[86, 200] current loss: 0.0003541460037231445\n",
      "[86, 300] current loss: 0.00028957557678222656\n",
      "[86, 400] current loss: 0.00027512550354003907\n",
      "[86, 500] current loss: 0.00024651384353637694\n",
      "[86, 600] current loss: 0.00025463056564331056\n",
      "[86, 700] current loss: 0.00034515619277954103\n",
      "[86, 800] current loss: 0.0002861948013305664\n",
      "[86, 900] current loss: 0.0003018364906311035\n",
      "[87, 100] current loss: 0.00022540521621704102\n",
      "[87, 200] current loss: 0.00034252595901489255\n",
      "[87, 300] current loss: 0.00028055429458618164\n",
      "[87, 400] current loss: 0.0002659411430358887\n",
      "[87, 500] current loss: 0.0002401103973388672\n",
      "[87, 600] current loss: 0.00024746084213256834\n",
      "[87, 700] current loss: 0.00033347082138061526\n",
      "[87, 800] current loss: 0.000277043342590332\n",
      "[87, 900] current loss: 0.0002925739288330078\n",
      "[88, 100] current loss: 0.0002187623977661133\n",
      "[88, 200] current loss: 0.0003315014839172363\n",
      "[88, 300] current loss: 0.0002716479301452637\n",
      "[88, 400] current loss: 0.0002577328681945801\n",
      "[88, 500] current loss: 0.00023323774337768554\n",
      "[88, 600] current loss: 0.0002408757209777832\n",
      "[88, 700] current loss: 0.00032275581359863284\n",
      "[88, 800] current loss: 0.0002680087089538574\n",
      "[88, 900] current loss: 0.0002841386795043945\n",
      "[89, 100] current loss: 0.00021245670318603514\n",
      "[89, 200] current loss: 0.00032103252410888673\n",
      "[89, 300] current loss: 0.00026332378387451173\n",
      "[89, 400] current loss: 0.00024941015243530276\n",
      "[89, 500] current loss: 0.00022687768936157228\n",
      "[89, 600] current loss: 0.00023399972915649414\n",
      "[89, 700] current loss: 0.0003123321533203125\n",
      "[89, 800] current loss: 0.00025953817367553713\n",
      "[89, 900] current loss: 0.00027614259719848636\n",
      "[90, 100] current loss: 0.0002068920135498047\n",
      "[90, 200] current loss: 0.0003117985725402832\n",
      "[90, 300] current loss: 0.00025544261932373047\n",
      "[90, 400] current loss: 0.00024164915084838866\n",
      "[90, 500] current loss: 0.0002207207679748535\n",
      "[90, 600] current loss: 0.0002283811569213867\n",
      "[90, 700] current loss: 0.0003028607368469238\n",
      "[90, 800] current loss: 0.0002521834373474121\n",
      "[90, 900] current loss: 0.0002686367034912109\n",
      "[91, 100] current loss: 0.00020172834396362305\n",
      "[91, 200] current loss: 0.0003024420738220215\n",
      "[91, 300] current loss: 0.0002481069564819336\n",
      "[91, 400] current loss: 0.000234342098236084\n",
      "[91, 500] current loss: 0.00021541786193847657\n",
      "[91, 600] current loss: 0.00022261953353881837\n",
      "[91, 700] current loss: 0.00029291057586669923\n",
      "[91, 800] current loss: 0.00024421262741088865\n",
      "[91, 900] current loss: 0.0002609801292419434\n",
      "[92, 100] current loss: 0.0001963486671447754\n",
      "[92, 200] current loss: 0.00029418039321899416\n",
      "[92, 300] current loss: 0.0002409844398498535\n",
      "[92, 400] current loss: 0.0002272176742553711\n",
      "[92, 500] current loss: 0.00020956993103027344\n",
      "[92, 600] current loss: 0.00021697998046875\n",
      "[92, 700] current loss: 0.00028461790084838864\n",
      "[92, 800] current loss: 0.0002379307746887207\n",
      "[92, 900] current loss: 0.00025368595123291017\n",
      "[93, 100] current loss: 0.00019153547286987303\n",
      "[93, 200] current loss: 0.0002857298851013184\n",
      "[93, 300] current loss: 0.00023496770858764647\n",
      "[93, 400] current loss: 0.000221224308013916\n",
      "[93, 500] current loss: 0.00020461511611938476\n",
      "[93, 600] current loss: 0.00021178102493286133\n",
      "[93, 700] current loss: 0.000275909423828125\n",
      "[93, 800] current loss: 0.00023121118545532226\n",
      "[93, 900] current loss: 0.0002466707229614258\n",
      "[94, 100] current loss: 0.0001871800422668457\n",
      "[94, 200] current loss: 0.000278505802154541\n",
      "[94, 300] current loss: 0.00022854518890380859\n",
      "[94, 400] current loss: 0.00021475648880004883\n",
      "[94, 500] current loss: 0.00019972658157348634\n",
      "[94, 600] current loss: 0.00020688438415527344\n",
      "[94, 700] current loss: 0.00026842689514160157\n",
      "[94, 800] current loss: 0.00022521018981933594\n",
      "[94, 900] current loss: 0.00024039459228515625\n",
      "[95, 100] current loss: 0.0001830434799194336\n",
      "[95, 200] current loss: 0.00027121448516845704\n",
      "[95, 300] current loss: 0.00022305011749267577\n",
      "[95, 400] current loss: 0.0002094564437866211\n",
      "[95, 500] current loss: 0.00019476652145385741\n",
      "[95, 600] current loss: 0.0002023649215698242\n",
      "[95, 700] current loss: 0.00026133012771606444\n",
      "[95, 800] current loss: 0.00021985149383544922\n",
      "[95, 900] current loss: 0.00023420047760009765\n",
      "[96, 100] current loss: 0.0001788158416748047\n",
      "[96, 200] current loss: 0.0002642960548400879\n",
      "[96, 300] current loss: 0.00021706438064575195\n",
      "[96, 400] current loss: 0.00020322656631469727\n",
      "[96, 500] current loss: 0.0001899847984313965\n",
      "[96, 600] current loss: 0.00019794750213623046\n",
      "[96, 700] current loss: 0.00025463104248046875\n",
      "[96, 800] current loss: 0.00021437358856201172\n",
      "[96, 900] current loss: 0.00022842645645141602\n",
      "[97, 100] current loss: 0.00017495346069335937\n",
      "[97, 200] current loss: 0.00025769662857055663\n",
      "[97, 300] current loss: 0.00021200990676879884\n",
      "[97, 400] current loss: 0.0001987457275390625\n",
      "[97, 500] current loss: 0.0001857757568359375\n",
      "[97, 600] current loss: 0.00019350290298461914\n",
      "[97, 700] current loss: 0.00024766063690185544\n",
      "[97, 800] current loss: 0.00020909929275512694\n",
      "[97, 900] current loss: 0.00022285175323486327\n",
      "[98, 100] current loss: 0.00017136430740356446\n",
      "[98, 200] current loss: 0.0002516016960144043\n",
      "[98, 300] current loss: 0.0002065272331237793\n",
      "[98, 400] current loss: 0.00019360923767089845\n",
      "[98, 500] current loss: 0.00018174266815185547\n",
      "[98, 600] current loss: 0.0001891489028930664\n",
      "[98, 700] current loss: 0.00024189186096191406\n",
      "[98, 800] current loss: 0.0002044072151184082\n",
      "[98, 900] current loss: 0.00021767902374267577\n",
      "[99, 100] current loss: 0.0001677536964416504\n",
      "[99, 200] current loss: 0.0002457432746887207\n",
      "[99, 300] current loss: 0.0002019033432006836\n",
      "[99, 400] current loss: 0.00018923139572143554\n",
      "[99, 500] current loss: 0.00017805099487304686\n",
      "[99, 600] current loss: 0.00018499469757080078\n",
      "[99, 700] current loss: 0.00023572301864624022\n",
      "[99, 800] current loss: 0.00019977951049804688\n",
      "[99, 900] current loss: 0.00021218538284301758\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False) # loss_fn - функция потерь. Выбрали КроссЭнтропию\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate) # Метод оптимизации выбрали SGD - стохастический градиент\n",
    "\n",
    "for epoch_num  in range(NUM_EPOCHS): # Одна эпоха (epoch) алгоритма оптимизации -- это проход по всей выборке.\n",
    "    iter_num = 0                     # Одна итерация (iteration) алгоритма оптимизации -- это проход по одному батчу.\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE): # Цикл по батчам\n",
    "        # forward (подсчёт ответа с текущими весами)\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # вычисляем loss'ы\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # выводем качество каждые 2000 батчей \n",
    "            \n",
    "        if iter_num % 100 == 99:\n",
    "            print('[{}, {}] current loss: {}'.format(epoch_num, iter_num + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # зануляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward (подсчёт новых градиентов)\n",
    "        loss.backward()\n",
    "\n",
    "        # обновляем веса\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the accuracy of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "53sTzgR5sPy0",
    "outputId": "e64a3210-2bd1-41d5-80e1-f1f8b0b4cf70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 100 %\n",
      "Accuracy of Trouser : 100 %\n",
      "Accuracy of Pullover : 100 %\n",
      "Accuracy of Dress : 100 %\n",
      "Accuracy of  Coat : 100 %\n",
      "Accuracy of Sandal : 100 %\n",
      "Accuracy of Shirt : 100 %\n",
      "Accuracy of Sneaker : 100 %\n",
      "Accuracy of   Bag : 100 %\n",
      "Accuracy of Ankle boot : 100 %\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        y_pred = model(X_batch)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == y_batch).squeeze()\n",
    "        for i in range(len(y_pred)):\n",
    "            label = y_batch[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "class_correct_total = 0\n",
    "class_correct_total_total = 0\n",
    "for i in range(num_classes):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    class_correct_total += class_correct[i]\n",
    "    class_correct_total_total += class_total[i]\n",
    "result = class_correct_total / class_correct_total_total\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EwZ2aLoesdvv",
    "outputId": "4cc74596-18d8-4333-94a1-a6568ea232ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2,  ..., 8, 8, 1], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model(torch.cuda.FloatTensor(X_test).view(-1, 1, 28, 28))\n",
    "_, predicted = torch.max(y_test_pred, 1)\n",
    "\n",
    "predicted.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating csv file with prediction answers to submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKSmfjy7tI4e"
   },
   "outputs": [],
   "source": [
    "answer_df = pd.DataFrame(data=predicted.cpu().numpy(), columns=['Category'])\n",
    "# answer_df.head()\n",
    "answer_df['Id'] = answer_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzg7hxVVtLi8"
   },
   "outputs": [],
   "source": [
    "answer_df.to_csv('./baseline3.csv', index=False)\n",
    "from google.colab import files\n",
    "files.download('baseline3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KyVpn89xx_g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Solution_Fashin-MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
